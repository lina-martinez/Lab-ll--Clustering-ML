{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research about the Spectral Clustering method, and answer the following questions:**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*a. In which cases might it be more useful to apply?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral clustering is a technique used in situations where the data is not linearly separable. It is particularly useful for high-dimensional data and can be effective in detecting patrons or irregularly shaped clusters, is very useful when a measure of the center and spread of the cluster is not a suitable description of the complete cluster."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*b. What are the mathematical fundamentals of it?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral Clustering uses spectral decomposition to project the data into a lower-dimensional space where clustering techniques can be applied, it is based on graph theory and eigenvalue analysis and its goal is to find a low-rank representation of the data similarity matrix. Spectral clustering uses information from the eigenvalues (the spectrum) to identify communities of nodes in a graph based on the edges connecting them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*c. What is the algorithm to compute it?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm to calculate Spectral Clustering is built from:\n",
    "\n",
    "* First, a data set is taken and the similarity between them is calculated to obtain the similarity matrix.\n",
    "* From the similarity matrix, the normalized Laplacian matrix is calculated. This matrix is important because it allows us to measure the connectivity between the data and how they are related to each other.\n",
    "* Then the first k eigenvectors of the normalized Laplacian matrix are calculated. These eigenvectors help us find the underlying structure in the data.\n",
    "* The eigenvectors are used to create a new matrix and normalize the rows. This reduced matrix is a compact representation of the original data and is used for clustering.\n",
    "* Finally, a clustering algorithm, such as KMeans or KMedoids, is applied to the reduced matrix to assign the data to different clusters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*d. Does it hold any relation to some of the concepts previously mentioned in class? Which, and how?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral clustering projects data into a lower dimensional space using eigenvectors and eigenvalues, similar to the dimensionality reduction technique of PCA. Both methods use eigenvectors and eigenvalues to describe the data in a lower dimension.\n",
    "\n",
    "In addition, spectral clustering also uses a clustering algorithm after the data projection step. This algorithm is similar to KMeans, which we also studied in class.\n",
    "\n",
    "Another technique similar to Spectral Clustering is T-SNE, which also uses a matrix to describe the probability that one data point is close to another, and is used to visualize high-dimensional data in a low-dimensional space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
